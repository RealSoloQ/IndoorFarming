{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies, check GPU availability, and add RAFT/core to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "print(o3d.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m) \u001b[38;5;66;03m# Suppress import warnings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) # Suppress import warnings\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "sys.path.append('../RAFT/core') # Add to path\n",
    "sys.path.append('../YOLO_UR5') # Add to path\n",
    "sys.path.append('../YOLO_UR5/utils')\n",
    "# Add the parent directory of 'main' to the Python path\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname('main.ipynb'), os.pardir))\n",
    "sys.path.append(os.path.join(parent_dir, 'RAFT'))\n",
    "\n",
    "from core.raft import RAFT\n",
    "from core.utils import flow_viz\n",
    "from core.utils.utils import InputPadder\n",
    "\n",
    "\n",
    "print(\"Is torch.cuda available? \", torch.cuda.is_available())\n",
    "print(\"Device Count: \",torch.cuda.device_count())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    curr_device = 'cuda'\n",
    "    print(\"Device Name: \", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    curr_device = 'cpu'\n",
    "\n",
    "# curr_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "# yolo_directory = os.path.join(curr_dir, 'YOLO_UR5')\n",
    "# sys.path.add(yolo_directory)\n",
    "\n",
    "# import run_YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, device):\n",
    "    return torch.from_numpy(img).permute(2, 0, 1).float()[None].to(device)\n",
    "\n",
    "\n",
    "def load_model(weights_path, args):\n",
    "    model = RAFT(args)\n",
    "    pretrained_weights = torch.load(\n",
    "        weights_path, map_location=torch.device(curr_device)) # Change to cuda if available\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.load_state_dict(pretrained_weights)\n",
    "    model.to(curr_device) # Change to cuda if available\n",
    "    return model\n",
    "\n",
    "\n",
    "def inference(model, frame1, frame2, device, pad_mode='sintel', iters=12, flow_init=None, upsample=True, test_mode=True):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # preprocess\n",
    "        frame1 = process_img(frame1, device)\n",
    "        frame2 = process_img(frame2, device)\n",
    "\n",
    "        padder = InputPadder(frame1.shape, mode=pad_mode)\n",
    "        frame1, frame2 = padder.pad(frame1, frame2)\n",
    "\n",
    "        # predict flow\n",
    "        if test_mode:\n",
    "            flow_low, flow_up = model(frame1, frame2, iters=iters, flow_init=flow_init, upsample=upsample, test_mode=test_mode)\n",
    "            return flow_low, flow_up\n",
    "\n",
    "        else:\n",
    "            flow_iters = model(frame1, frame2, iters=iters, flow_init=flow_init, upsample=upsample, test_mode=test_mode)\n",
    "            return flow_iters\n",
    "\n",
    "\n",
    "def get_viz(flo):\n",
    "    flo = flo[0].permute(1, 2, 0).cpu().numpy()\n",
    "    return flow_viz.flow_to_image(flo)\n",
    "\n",
    "# sketchy class to pass to RAFT\n",
    "class Args():\n",
    "    def __init__(self, model='', path='', small=False, mixed_precision=True, alternate_corr=False):\n",
    "        self.model = model\n",
    "        self.path = path\n",
    "        self.small = small\n",
    "        self.mixed_precision = mixed_precision\n",
    "        self.alternate_corr = alternate_corr\n",
    "\n",
    "    \"\"\" Sketchy hack to pretend to iterate through the class objects \"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        raise StopIteration\n",
    "    \n",
    "# Converts pixel location (either matrix of pixels or single pixel) to tool frame coordinate system\n",
    "def pix_to_pos(pixel_x, pixel_y, flow_x_matrix, image_center_x, image_center_y):\n",
    "\n",
    "    # Declare stereo related variables\n",
    "    baseline_x = 0.005\n",
    "    tilt = np.radians(0) \n",
    "    focal_length = 891.77161 \n",
    "    cam_x_offset = 0.000 \n",
    "    cam_y_offset = 0.000\n",
    "    pitch_angle = np.radians(0) \n",
    "\n",
    "    # Calculations\n",
    "    world_conversion = baseline_x * np.cos(tilt) / flow_x_matrix # Calculating pixel to world conversion\n",
    "    x_offsets = cam_x_offset - baseline_x # Including camera offset from center of gripper (if using a horizontal offset)\n",
    "    x_translation_matrix = world_conversion * (image_center_x - pixel_x) # Calculating x translation using world conversion\n",
    "\n",
    "    y_offsets = cam_y_offset\n",
    "    pitch_offset = -((baseline_x * focal_length) / flow_x_matrix) * np.sin(pitch_angle) # Essentially using z-depth to find pitch offset\n",
    "    y_translation_matrix = -world_conversion * (image_center_y - pixel_y) # Negated because camera is flipped upside down to match camera axes\n",
    "\n",
    "    z_coord = ((baseline_x * focal_length) / -flow_x_matrix) # 2D matrix of depth values for each pixel in image\n",
    "    # print(z_coord)\n",
    "    x_coord = x_offsets - x_translation_matrix # 2D matrix of x-coordinate values for each pixel in image\n",
    "    y_coord = pitch_offset + y_offsets + y_translation_matrix # 2D matrix of y-coordinate values for each pixel in image\n",
    "\n",
    "    # Tuning matrix by getting rid of negative depths and zeros and make them infinity\n",
    "    z_coord = np.where(z_coord <= 0, np.inf, z_coord) \n",
    "\n",
    "    return x_coord, y_coord, z_coord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run YOLO on Images to Identify Blackberries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# annotated_image_1, berry_centroids_1 = YOLO.apply_yolo_to_image('2.5mm_1.png')\n",
    "# annotated_image_2, berry_centroids_2 = YOLO.apply_yolo_to_image('2.5mm_2.png')\n",
    "\n",
    "# # print(berry_centroids_1)\n",
    "# # print(berry_centroids_2)\n",
    "\n",
    "# # print(annotated_image_1.shape)\n",
    "# # print(annotated_image_2.shape)\n",
    "\n",
    "# image_center_x = annotated_image_1.shape[1] / 2\n",
    "# image_center_y = annotated_image_1.shape[0] / 2\n",
    "\n",
    "# # print(image_center_x)\n",
    "# # print(image_center_y)\n",
    "\n",
    "# frame_1_centroid_x = berry_centroids_1[:, 0]\n",
    "# frame_1_centroid_y = berry_centroids_1[:, 1]\n",
    "\n",
    "# # print(frame_1_centroid_x)\n",
    "# # print(frame_1_centroid_y)\n",
    "\n",
    "# x_disparity = np.abs(berry_centroids_2 - berry_centroids_1)[:, 0]\n",
    "\n",
    "# # print(x_disparity)\n",
    "\n",
    "# # berry1_x = frame_1_centroid_x[0]\n",
    "# # berry1_y = frame_1_centroid_y[0]\n",
    "\n",
    "# berries_x_pos, berries_y_pos, berries_z_pos = pix_to_pos(frame_1_centroid_x, frame_1_centroid_y, x_disparity, image_center_x, image_center_y)\n",
    "# berries_pos_matrix = np.column_stack((berries_x_pos, berries_y_pos, berries_z_pos))\n",
    "# print(\"Berry Positions (m): \")\n",
    "# print(berries_pos_matrix)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(15, 10))\n",
    "# axes[0].imshow(annotated_image_1)\n",
    "# axes[0].set_title('YOLO Berry Detection - Image 1')\n",
    "# axes[1].imshow(annotated_image_2)\n",
    "# axes[1].set_title('YOLO Berry Detection - Image 2')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Model on Desired Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"../RAFT/models/raft-sintel.pth\", args=Args())\n",
    "frame1 = cv2.imread('Frame1_5mm.png')\n",
    "frame2 = cv2.imread('Frame2_5mm.png')\n",
    "\n",
    "# Downsample image to reduce computation complexity (using Lanczos4 downsampling algorithm)\n",
    "frame1 = cv2.resize(frame1, (320, 240), interpolation=cv2.INTER_LANCZOS4)\n",
    "frame2 = cv2.resize(frame2, (320, 240), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "print(frame1.shape)\n",
    "\n",
    "# Convert images to rgb color space\n",
    "frame1_rgb = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB)\n",
    "frame2_rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Resize the second image to match the dimensions of the first image\n",
    "height, width, channels = frame2.shape\n",
    "frame1 = cv2.resize(frame1_rgb, (width, height))\n",
    "\n",
    "# Apply RAFT Optical Flow Model on Frame 1 and 2\n",
    "time1 = time.perf_counter()\n",
    "flow_iters = inference(model, frame1, frame2_rgb, device=curr_device, iters=5, test_mode=False)\n",
    "time2 = time.perf_counter()\n",
    "print(\"Inference Time: \", time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Model Inference for Optical Flow from Frame 1 to Frame 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig2, axes = plt.subplots(3, 2, figsize=(18, 12), gridspec_kw={'height_ratios': [4, 4, 1]})\n",
    "fig2.subplots_adjust(hspace=0.3)\n",
    "axes[0, 0].imshow(frame1)\n",
    "axes[0, 0].set_title(\"Frame 1\")\n",
    "axes[0, 1].imshow(frame2)\n",
    "axes[0, 1].set_title(\"Frame 2\")\n",
    "\n",
    "first_flow_viz = axes[1, 0].imshow(get_viz(flow_iters[0]))\n",
    "axes[1, 0].set_title('First RAFT Flow Iteration (Frame 1)')\n",
    "axes[1, 0].set_xlabel(\"Pixels\"); axes[1, 0].set_ylabel(\"Pixels\")\n",
    "final_flow_viz = axes[1, 1].imshow(get_viz(flow_iters[-1]))\n",
    "axes[1, 1].set_title('Final RAFT Flow Results (Frame 1)')\n",
    "axes[1, 1].set_xlabel(\"Pixels\"); axes[1, 1].set_ylabel(\"Pixels\")\n",
    "\n",
    "# Add color bars\n",
    "axes[2, 0].axis('off'); axes[2, 1].axis('off')\n",
    "cbar0 = fig2.colorbar(first_flow_viz, ax=axes[2, :], fraction=0.4, pad=0.04, location=\"top\")\n",
    "cbar0.set_label('Magnitude of Optical Flow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Iteration Flow Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve final flow iteration and the corresponding flow tensors for x and y\n",
    "final_flow = flow_iters[-1]\n",
    "flow_x_matrix = final_flow[0, 0]  # Horizontal displacement component in pixels\n",
    "flow_y_matrix = final_flow[0, 1]  # Vertical displacement component in pixels\n",
    "\n",
    "# Compute the magnitude of flow\n",
    "flow_magnitude = torch.sqrt(flow_x_matrix**2 + flow_y_matrix**2)\n",
    "\n",
    "# Convert flow tensors to numpy arrays and round all points to 4 decimal places\n",
    "flow_x_matrix = np.round(flow_x_matrix.cpu().numpy(), decimals=4) # Tensor to numpy array can only be done on CPU\n",
    "flow_y_matrix = np.round(flow_y_matrix.cpu().numpy(), decimals=4)\n",
    "flow_magnitude = np.round(flow_magnitude.cpu().numpy(), decimals=4)\n",
    "\n",
    "np.savetxt('flow_x_matrix.txt', flow_x_matrix)\n",
    "np.savetxt('flow_y_matrix.txt', flow_y_matrix)\n",
    "np.savetxt('flow_magnitude.txt', flow_magnitude)\n",
    "\n",
    "# Extra Information\n",
    "max_index = np.unravel_index(np.argmax(flow_x_matrix, axis=None), flow_x_matrix.shape)\n",
    "print(\"Index of maximum flow-x value:\", max_index)\n",
    "baseline_x = 0.005\n",
    "tilt = np.radians(0) \n",
    "print(\"Maximum Flow in x-direction :\", np.max(flow_x_matrix), \"pixels\")\n",
    "print(\"Minimum Flow in x-direction :\", np.min(flow_x_matrix), \"pixels\")\n",
    "\n",
    "# Calculating pixel to world conversion\n",
    "world_conversion = baseline_x * np.cos(tilt) / np.max(flow_x_matrix) \n",
    "print(\"Pixels per mm at the depth where max disparity is: \", (1 / world_conversion) / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Flow Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply threshold to flow magnitude\n",
    "flow_threshold = 12  # Pixel displacement threshold value\n",
    "flow_magnitude_filtered = np.where(flow_magnitude < flow_threshold, 0, flow_magnitude) # New matrix of pixels that turn black (value set to 0) if not passing flow threshold\n",
    "removed_indices = np.where(flow_magnitude_filtered == 0)\n",
    "\n",
    "# Visualize the thresholded flow magnitude\n",
    "plt.imshow(flow_magnitude_filtered, cmap='gray')\n",
    "plt.title('Thresholded Flow Magnitude')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# Adjust Flow matrices so that the filtered out pixels are set to infinity so they can be ignored for later processing\n",
    "flow_x_matrix[removed_indices] = np.inf\n",
    "flow_y_matrix[removed_indices] = np.inf\n",
    "\n",
    "# Creating Matrix of Pixels\n",
    "height, width, channels = final_flow_viz.get_array().shape\n",
    "\n",
    "# Create arrays representing the x and y coordinates of pixels\n",
    "x_coords = np.tile(np.arange(width), height)\n",
    "y_coords = np.repeat(np.arange(height), width)\n",
    "\n",
    "# Reshape x_coords and y_coords to match the shape of the image\n",
    "x_coords = x_coords.reshape(height, width)\n",
    "y_coords = y_coords.reshape(height, width)\n",
    "\n",
    "# Stack x_coords and y_coords to create the matrix of pixels\n",
    "pixel_matrix = np.dstack((x_coords, y_coords))\n",
    "x_pix_matrix = pixel_matrix[:, :, 0]\n",
    "y_pix_matrix = pixel_matrix[:, :, 1]\n",
    "\n",
    "# print(\"X Pixel Matrix Shape: \", x_pix_matrix.shape)\n",
    "# print(\"Y Pixel Matrix Shape: \", y_pix_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X, Y, Z Location of Each Pixel in Frame 1 with Respect to Tool Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get matrices of (x, y, z) locations for each pixel in image\n",
    "im_center_x = final_flow[0][0].shape[1] / 2\n",
    "print(im_center_x)\n",
    "im_center_y = final_flow[0][0].shape[0] / 2 \n",
    "print(im_center_y)\n",
    "x_pos_matrix, y_pos_matrix, z_pos_matrix = pix_to_pos(x_pix_matrix, y_pix_matrix, flow_x_matrix, im_center_x, im_center_y) \n",
    "print(z_pos_matrix.shape)\n",
    "kept_indices = np.where(np.isfinite(z_pos_matrix))\n",
    "\n",
    "x_pos_filtered = x_pos_matrix[kept_indices]\n",
    "y_pos_filtered = y_pos_matrix[kept_indices]\n",
    "z_pos_filtered = z_pos_matrix[kept_indices]     \n",
    "obstacle_3d_points = np.column_stack((x_pos_filtered, y_pos_filtered, z_pos_filtered))\n",
    "\n",
    "print(\"Obstacle Points Shape: \", obstacle_3d_points.shape)\n",
    "\n",
    "print(\"\\nMaximum finite x value (m): \", np.round(np.max(x_pos_matrix[np.isfinite(x_pos_matrix)]), decimals=4))\n",
    "print(\"Minimum x value (m): \", np.round(np.min(x_pos_matrix), decimals=4))\n",
    "\n",
    "print(\"\\nMaximum finite y value (m): \", np.round(np.max(y_pos_matrix[np.isfinite(y_pos_matrix)]), decimals=4))\n",
    "print(\"Minimum y value (m): \", np.round(np.min(y_pos_matrix), decimals=4))\n",
    "\n",
    "print(\"\\nMaximum finite z value (m): \", np.round(np.max(z_pos_matrix[np.isfinite(z_pos_matrix)]), decimals=4))\n",
    "print(\"Minimum depth value (m): \", np.round(np.min(z_pos_matrix), decimals=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.subplots as subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create 3D point cloud plot using plotly\n",
    "fig_3d = px.scatter_3d(x=x_pos_filtered, y=y_pos_filtered, z=z_pos_filtered, color=z_pos_filtered,\n",
    "                            opacity=1, size_max=5, color_continuous_scale='Viridis')\n",
    "fig_3d.update_layout(title='3D Point Cloud', coloraxis_colorbar=dict(title='Z_Depth Magnitude'), width=1000, height=500)\n",
    "fig_3d.show()\n",
    "\n",
    "fig_2d = px.scatter(x=x_pos_filtered, y=y_pos_filtered)\n",
    "fig_2d.update_layout(title='XY View of Point Cloud')\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Point Cloud Information to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save as .ply point cloud file\n",
    "# import open3d as o3d\n",
    "\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "# points = o3d.utility.Vector3dVector(obstacle_3d_points) # Convert numpy array to Open3D Vector\n",
    "# pcd.points = points\n",
    "# o3d.io.write_point_cloud(\"obstacle_point_cloud.ply\", pcd)\n",
    "\n",
    "# # Save as .txt file\n",
    "# np.savetxt('point_cloud_txt.txt', obstacle_3d_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17.0\n",
      "FEngine (64 bits) created at 0x2d9778000 (threading is enabled)\n",
      "FEngine resolved backend: OpenGL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[error] GLFW error: Cocoa: Failed to find service port for display\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "print(o3d.__version__)\n",
    "\n",
    "# Define example obstacle points\n",
    "obstacle_3d_points = np.random.rand(100, 3)  # Assuming 100 points with 3 coordinates each\n",
    "\n",
    "# Define example frame1 and kept_indices\n",
    "frame1 = np.random.randint(0, 255, size=(480, 640, 3), dtype=np.uint8)  # Example frame1 image\n",
    "kept_indices = np.random.choice(np.arange(frame1.shape[0]), size=50, replace=False)  # Example kept_indices\n",
    "\n",
    "\n",
    "# o3d.visualization.webrtc_server.enable_webrtc()\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "points = o3d.utility.Vector3dVector(obstacle_3d_points) # Convert numpy array to Open3D Vector\n",
    "pcd.points = points\n",
    "\n",
    "# frame1_colors = frame1[kept_indices] # Extracting pixels that are kept after threshold \n",
    "# frame1_colors_norm = frame1_colors / 255.0 # Normalize color values to [0, 1]\n",
    "# print(frame1_colors_norm[0])\n",
    "\n",
    "# colors = o3d.utility.Vector3dVector(frame1_colors_norm)\n",
    "# pcd.colors = colors\n",
    "\n",
    "# voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=0.001)\n",
    "# o3d.visualization.draw_geometries([voxel_grid])\n",
    "\n",
    "# Create a coordinate frame: x-axis -> red, y-axis -> green, z-axis -> blue\n",
    "coordinate_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1, origin=[0, 0, 0])\n",
    "\n",
    "octree = o3d.geometry.Octree(max_depth=4)\n",
    "octree.convert_from_point_cloud(pcd, size_expand=0.01)\n",
    "o3d.visualization.draw([octree, coordinate_frame])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Voxel Grid Using Open3D Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "# import os\n",
    "\n",
    "# # Parameters class holding variables that change in the callback function\n",
    "# class Params:\n",
    "#     # counter for selecting a new voxel size\n",
    "#     sizes_counter = 0\n",
    "#     # array of voxel sizes between 0.01 and 0.1\n",
    "#     voxel_sizes = np.arange(0.001)\n",
    "#     # empty TriangleMesh object that will contain the cubes\n",
    "#     vox_mesh = o3d.geometry.TriangleMesh()\n",
    "#     # boolean value used for initial initialization of the voxel mesh\n",
    "#     initialize = True\n",
    "\n",
    "# # Callback function used to construct and rotate the voxel meshes\n",
    "# def rotate_and_change(vis):\n",
    "#     # When the sizes_counter is 0 generate the voxel grid and construct the voxel mesh\n",
    "#     if Params.sizes_counter == 0:\n",
    "#         # generate the voxel grid using the voxel sizes setup in the params class\n",
    "#         voxel_grid = o3d.geometry.VoxelGrid.create_from_point_cloud(pcd, voxel_size=Params.voxel_sizes[Params.sizes_counter])\n",
    "#         # get all voxels in the voxel grid\n",
    "#         voxels_all = voxel_grid.get_voxels()\n",
    "#         # get the calculated size of a voxel\n",
    "#         voxel_size = voxel_grid.voxel_size\n",
    "#         # loop through all the voxels\n",
    "#         for voxel in voxels_all:\n",
    "#             # create a cube mesh with a size 1x1x1\n",
    "#             cube = o3d.geometry.TriangleMesh.create_box(width=1, height=1, depth=1)\n",
    "#             # paint it with the color of the current voxel\n",
    "#             cube.paint_uniform_color(voxel.color)\n",
    "#             # scale the box using the size of the voxel\n",
    "#             cube.scale(voxel_size, center=cube.get_center())\n",
    "#             # get the center of the current voxel\n",
    "#             voxel_center = voxel_grid.get_voxel_center_coordinate(voxel.grid_index)\n",
    "#             # translate the box to the center of the voxel\n",
    "#             cube.translate(voxel_center, relative=False)\n",
    "#             # add the box to the TriangleMesh object\n",
    "#             Params.vox_mesh += cube\n",
    "\n",
    "#         # on the first run of the callback loop initialize the Triangle mesh by adding it to the Visualizer. In subsequent iterations just update the geometry\n",
    "#         if Params.initialize:\n",
    "#             vis.add_geometry(Params.vox_mesh)\n",
    "#             Params.initialize = False\n",
    "#         else:\n",
    "#             vis.update_geometry(Params.vox_mesh)\n",
    "\n",
    "#     vis.update_renderer()\n",
    "\n",
    "# # Initialize a point cloud object\n",
    "# pcd = o3d.geometry.PointCloud()\n",
    "\n",
    "# # Add the points, colors and normals as Vectors\n",
    "# pcd.points = o3d.utility.Vector3dVector(obstacle_3d_points)\n",
    "# # pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "# # pcd.normals = o3d.utility.Vector3dVector(normals)\n",
    "\n",
    "# # Initialize a visualizer object\n",
    "# vis = o3d.visualization.Visualizer()\n",
    "\n",
    "# # Create a window, name it and scale it\n",
    "# vis.create_window(window_name=\"Obstacle Visualization\", width=1000, height=800)\n",
    "\n",
    "# # Add the point cloud and create a 3D axis for reference\n",
    "# vis.add_geometry(pcd)\n",
    "# vis.add_geometry(o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.1))\n",
    "\n",
    "# # # Create text annotations for the axis labels\n",
    "# # x_label = o3d.geometry.TriangleMesh.create_text(\"X\", 10, 1, False, False)\n",
    "# # y_label = o3d.geometry.TriangleMesh.create_text(\"Y\", 10, 1, False, False)\n",
    "# # z_label = o3d.geometry.TriangleMesh.create_text(\"Z\", 10, 1, False, False)\n",
    "\n",
    "# # # Position the labels along the axes\n",
    "# # x_label.translate([1.1, 0, 0])  # Position the X label along the X-axis\n",
    "# # y_label.translate([0, 1.1, 0])  # Position the Y label along the Y-axis\n",
    "# # z_label.translate([0, 0, 1.1])  # Position the Z label along the Z-axis\n",
    "\n",
    "# # Register the callback function\n",
    "# vis.register_animation_callback(rotate_and_change)\n",
    "\n",
    "# # We run the visualizer\n",
    "# vis.run()\n",
    "\n",
    "# # Once the visualizer is closed destroy the window and clean up\n",
    "# vis.destroy_window()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
